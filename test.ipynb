{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_to_element_format(value, max_element_value):\n",
    "    \"\"\"Квантование значения в представимый диапазон формата элемента.\"\"\"\n",
    "    if value > max_element_value:\n",
    "        return max_element_value\n",
    "    elif value < -max_element_value:\n",
    "        return -max_element_value\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "def convert_to_mx_format(tensor):\n",
    "    \"\"\"Преобразует тензор скалярных чисел в формат MX.\"\"\"\n",
    "    emax_elem = 127  # Для FP32, максимальная экспонента нормального числа\n",
    "    max_float32 = 3.4028235e38  # Максимальное представимое значение FP32\n",
    "\n",
    "    # Проверка на бесконечные и NaN значения\n",
    "    if torch.any(torch.isinf(tensor)) or torch.any(torch.isnan(tensor)):\n",
    "        raise ValueError(\"Входной тензор содержит бесконечные или NaN значения\")\n",
    "\n",
    "    # Вычисляем максимальное значение по модулю тензора\n",
    "    max_abs_value = torch.max(torch.abs(tensor))\n",
    "\n",
    "    # Если все элементы равны 0\n",
    "    if max_abs_value.item() == 0:\n",
    "        return 0, torch.zeros(tensor.size())\n",
    "\n",
    "    # 1. Вычисляем общий масштаб\n",
    "    shared_exp = int(torch.floor(torch.log2(max_abs_value))) - emax_elem\n",
    "    X = 2 ** shared_exp\n",
    "\n",
    "    # 2. Квантование элементов\n",
    "    P = []\n",
    "    for value in tensor:\n",
    "        # Нормируем значение\n",
    "        quantized_value = quantize_to_element_format(value / X, max_float32)\n",
    "        P.append(quantized_value)\n",
    "\n",
    "    return X, torch.tensor(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.tensor([1.0, 2.5, 3.0, -4.5, 0.0, 1.0e-10, 1.7], dtype=torch.float32)\n",
    "try:\n",
    "    X, P = convert_to_mx_format(input_tensor)\n",
    "    print(\"Общий масштаб X:\", X)\n",
    "    print(\"Квантованные элементы P:\", P)\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Настройки\n",
    "M, K, N = 4, 3, 2  # Размерности для матриц\n",
    "bfloat16 = torch.bfloat16  # Используем BFloat16\n",
    "\n",
    "# Инициализация входных данных и весов\n",
    "A_i_1 = torch.randn(M, K, dtype=torch.float32).to(bfloat16)  # Вход предыдущего слоя (BFloat16)\n",
    "W_i = torch.randn(K, N, dtype=torch.float32).to(bfloat16)  # Веса текущего слоя (BFloat16)\n",
    "\n",
    "# Прямой проход\n",
    "def forward_pass(A_i_1, W_i):\n",
    "    # Квантизация (в данном случае просто преобразуем в BFloat16)\n",
    "    A_i_1_quantized = A_i_1.to(bfloat16)\n",
    "    W_i_quantized = W_i.to(bfloat16)\n",
    "\n",
    "    # Матрица A_i (выход текущего слоя)\n",
    "    A_i = torch.matmul(A_i_1_quantized, W_i_quantized)\n",
    "\n",
    "    return A_i\n",
    "\n",
    "# Обратный проход\n",
    "def backward_pass(A_i_1, W_i, grad_output):\n",
    "    # Квантизация градиента (если нужно)\n",
    "    grad_output_quantized = grad_output.to(bfloat16)\n",
    "\n",
    "    # Вычисление градиентов\n",
    "    G_i = torch.matmul(A_i_1.T, grad_output_quantized)  # Градиенты по весам\n",
    "    grad_A_i_1 = torch.matmul(grad_output_quantized, W_i.T)  # Градиенты по A_i_1\n",
    "\n",
    "    return G_i, grad_A_i_1\n",
    "\n",
    "# Основной код\n",
    "A_i = forward_pass(A_i_1, W_i)\n",
    "print(\"A_i (выход текущего слоя):\")\n",
    "print(A_i)\n",
    "\n",
    "# Предположим, что у нас есть градиенты потерь по выходу\n",
    "grad_output = torch.randn(M, N, dtype=torch.float32)\n",
    "\n",
    "G_i, grad_A_i_1 = backward_pass(A_i_1, W_i, grad_output)\n",
    "print(\"\\nG_i (градиенты по весам):\")\n",
    "print(G_i)\n",
    "\n",
    "print(\"\\nГрадиенты по A_i_1:\")\n",
    "print(grad_A_i_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_i (выход текущего слоя):\n",
      "tensor([[-0.0391, -0.0972],\n",
      "        [ 0.1465, -0.1099],\n",
      "        [-0.0461, -0.1348],\n",
      "        [ 0.3926, -0.0669]], dtype=torch.bfloat16)\n",
      "\n",
      "Значение потерь:\n",
      "2.65625\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Настройки\n",
    "M, K, N = 4, 3, 2  # Размерности для матриц\n",
    "bfloat16 = torch.bfloat16  # Используем BFloat16\n",
    "\n",
    "# Определяем двуслойную нейронную сеть\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(K, N).to(bfloat16)  # Первый слой (вход K, выход N) в bfloat16\n",
    "        self.fc2 = nn.Linear(N, N).to(bfloat16)  # Второй слой (вход N, выход N) в bfloat16\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)  # Прямой проход через первый слой\n",
    "        x = F.relu(x)    # Применяем ReLU\n",
    "        x = self.fc2(x)  # Прямой проход через второй слой\n",
    "        return x\n",
    "\n",
    "# Инициализация сети\n",
    "model = SimpleNN()\n",
    "\n",
    "# Инициализация входных данных\n",
    "A_i_1 = torch.randn(M, K, dtype=torch.bfloat16)  # Входные данные (BFloat16)\n",
    "\n",
    "# Прямой проход\n",
    "def forward_pass(model, A_i_1):\n",
    "    model.eval()  # Устанавливаем режим оценки\n",
    "    with torch.no_grad():\n",
    "        A_i = model(A_i_1)  # Проходим через сеть\n",
    "    return A_i\n",
    "\n",
    "# Обратный проход\n",
    "def backward_pass(model, A_i_1, grad_output):\n",
    "    model.train()  # Устанавливаем режим обучения\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)  # Оптимизатор\n",
    "\n",
    "    # Прямой проход для получения предсказания\n",
    "    A_i = model(A_i_1)\n",
    "    A_i = A_i.cuda()\n",
    "    grad_output = grad_output.cuda()\n",
    "\n",
    "    # Вычисляем функцию потерь (например, среднеквадратичную ошибку)\n",
    "    loss = F.mse_loss(A_i, grad_output)\n",
    "    \n",
    "    # Обнуляем градиенты\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Обратный проход\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "# Основной код\n",
    "# Получаем выход нейронной сети\n",
    "A_i = forward_pass(model, A_i_1)\n",
    "print(\"A_i (выход текущего слоя):\")\n",
    "print(A_i)\n",
    "\n",
    "# Предположим, что у нас есть целевые градиенты (град. выход)\n",
    "grad_output = torch.randn(M, N, dtype=torch.bfloat16)  # Используем BFloat16 для целевых градиентов\n",
    "\n",
    "# Запускаем обратный проход и получаем значение потерь\n",
    "loss_value = backward_pass(model, A_i_1, grad_output)\n",
    "print(\"\\nЗначение потерь:\")\n",
    "print(loss_value)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
